{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a19c87-7f58-407f-9ada-44fb5ba80d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da25da67-40b2-4da1-b73d-ece3ef0cc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/images/checked\", exist_ok=True)\n",
    "os.makedirs(\"data/images/unchecked\", exist_ok=True)\n",
    "os.makedirs(\"data/images/ambiguous\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2665ff1d-d970-4d7c-afbb-0e91f1003f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "BOX_SIZE = 120\n",
    "\n",
    "samples = {\n",
    "    \"checked\": 100,\n",
    "    \"unchecked\": 100,\n",
    "    \"ambiguous\": 50\n",
    "}\n",
    "\n",
    "annotations = []\n",
    "\n",
    "def generate_checkbox(state, idx):\n",
    "    img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    x1 = (IMG_SIZE - BOX_SIZE) // 2\n",
    "    y1 = (IMG_SIZE - BOX_SIZE) // 2\n",
    "    x2, y2 = x1 + BOX_SIZE, y1 + BOX_SIZE\n",
    "    draw.rectangle([x1, y1, x2, y2], outline=\"black\", width=4)\n",
    "\n",
    "    if state == \"checked\":\n",
    "        draw.line([(x1+20,y1+60),(x1+50,y1+90),(x1+100,y1+30)], fill=\"black\", width=6)\n",
    "\n",
    "    elif state == \"ambiguous\":\n",
    "        draw.line([(x1+40,y1+60),(x1+70,y1+50)], fill=\"black\", width=4)\n",
    "        img = img.filter(ImageFilter.GaussianBlur(1.5))\n",
    "\n",
    "    img = img.rotate(random.uniform(-5, 5), fillcolor=\"white\")\n",
    "    return img\n",
    "\n",
    "for state, count in samples.items():\n",
    "    for i in range(count):\n",
    "        img = generate_checkbox(state, i)\n",
    "        path = f\"data/images/{state}/{state}_{i}.png\"\n",
    "        img.save(path)\n",
    "\n",
    "        annotations.append({\n",
    "            \"image\": path,\n",
    "            \"label\": state\n",
    "        })\n",
    "\n",
    "with open(\"data/annotations.json\", \"w\") as f:\n",
    "    json.dump(annotations, f, indent=2)\n",
    "\n",
    "print(\"Dataset created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ee5f4c-416f-4b8d-b24e-c21fd7b2f25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 223.5, 223.5, -0.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"data/images/ambiguous/ambiguous_0.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef60ce6-56cf-49cb-a0f7-47281450a847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce4b3490f564d73ba039f6fcf3c7ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=False\n",
    ")\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.float32,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ade578c-2711-456b-9015-b915319132d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_checkbox(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Classify the checkbox state. Answer with one word: checked, unchecked, or ambiguous.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(\n",
    "        text=prompt,\n",
    "        images=image,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=5)\n",
    "\n",
    "    result = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return result.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678e3f43-4b85-4bad-9788-b3a3f7bfc8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: system\n",
      "you are a helpful assistant.\n",
      "user\n",
      "classify the checkbox state. answer with one word: checked, unchecked, or ambiguous.\n",
      "assistant\n",
      "checked\n"
     ]
    }
   ],
   "source": [
    "test_img = \"data/images/checked/checked_0.png\"\n",
    "print(\"Prediction:\", predict_checkbox(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa50f39f-5b1e-4b71-a3c7-a9cf14c8a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                                                                                                                      ambiguous       0.00      0.00      0.00      10.0\n",
      "                                                                                                                                        checked       0.00      0.00      0.00      12.0\n",
      "system\n",
      "you are a helpful assistant.\n",
      "user\n",
      "classify the checkbox state. answer with one word: checked, unchecked, or ambiguous.\n",
      "assistant\n",
      "checked       0.00      0.00      0.00       0.0\n",
      "                                                                                                                                      unchecked       0.00      0.00      0.00       8.0\n",
      "\n",
      "                                                                                                                                       accuracy                           0.00      30.0\n",
      "                                                                                                                                      macro avg       0.00      0.00      0.00      30.0\n",
      "                                                                                                                                   weighted avg       0.00      0.00      0.00      30.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for sample in random.sample(annotations, 30):\n",
    "    pred = predict_checkbox(sample[\"image\"])\n",
    "    y_true.append(sample[\"label\"])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50749331-2cc9-495d-bdaa-7f73b82c7439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=[\"checked\", \"unchecked\", \"ambiguous\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac6aa70-6012-4c60-817b-38da9f6ed397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7cd0f361b64d31b24f70f1a08ece14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd3347404ac4bd3bfbd98989846ecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  82%|########1 | 3.26G/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-VL-2B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be0ed14f9584f758a1c4185f16a4a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f365038a0d41e7ad45589ad1755879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=False\n",
    ")\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.float32,   # CPU-safe\n",
    "    device_map=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5344c77c-f7c9-4f1d-977d-bb7df7ed3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Classify the checkbox state. Answer with one word: checked, unchecked, or ambiguous.\n",
      "assistant\n",
      "checked\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load image\n",
    "image = Image.open(\"data/images/checked/checked_0.png\").convert(\"RGB\")\n",
    "\n",
    "# Build Qwen-style message with IMAGE\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Classify the checkbox state. Answer with one word: checked, unchecked, or ambiguous.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Apply chat template (VERY IMPORTANT)\n",
    "text_prompt = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Process inputs\n",
    "inputs = processor(\n",
    "    text=text_prompt,\n",
    "    images=image,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Generate output\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=5\n",
    "    )\n",
    "\n",
    "# Decode result\n",
    "result = processor.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Model prediction:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d760574-c61d-4f89-9613-5860f56dfb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
